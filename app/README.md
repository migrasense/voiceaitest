
# ğŸ“˜ Servoice AI Voice Assistant â€“ Developer & Demo Documentation

## 1. System Overview

Servoice is a **voice-enabled assistant for senior care companies**.
It captures audio from a microphone or WebSocket, transcribes it in real time using **Deepgram**, analyzes intent with **Groq**, and broadcasts transcripts + AI responses to clients (e.g., a Vite UI).

**Main Flow:**

1. ğŸ¤ User speaks â†’ audio sent to `/audio` WebSocket
2. ğŸ“ Deepgram streams back live + final transcripts
3. ğŸ¤– Groq analyzes transcripts for **intent, urgency, language**
4. ğŸ“¡ Responses are broadcast to all connected clients via `/transcripts/stream`

---

## 2. Directory Layout

```
app/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py              # Global config & logging
â”‚   â”œâ”€â”€ connection_manager.py  # WebSocket manager (broadcasts to clients)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mock_response.py       # Pre-defined mock responses
â”‚   â”œâ”€â”€ mock_stt.py            # Mock STT with conversation history
â”‚
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ websocket_routes.py    # /audio + /transcripts/stream endpoints
â”‚   â”œâ”€â”€ mock_routes.py         # /mock/* endpoints (for Postman/testing)
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ groq_client.py         # Intent detection using Groq API
â”‚   â”œâ”€â”€ transcript_service.py  # Wraps Deepgram transcript handling
â”‚
â”œâ”€â”€ main.py                    # FastAPI entrypoint
â”œâ”€â”€ prompt_config.json         # Prompt/response config for Groq
â”‚
clients/
â”œâ”€â”€ mic_client.py              # Streams mic â†’ /audio
â”œâ”€â”€ mic_and_transcript_client.py # Streams mic + listens to transcripts
â”‚
tests/
â”œâ”€â”€ test_app.py                 # Basic FastAPI route tests
â”œâ”€â”€ test_websockets.py          # WebSocket connect tests
â”œâ”€â”€ test_deepgram_integration.py # Optional integration w/ Deepgram
```

---

## 3. Core Components

### A. FastAPI Server (`main.py`)

* Bootstraps app and includes all routers
* CORS enabled for UI connections
* Uses `lifespan` for startup/shutdown logs

### B. Deepgram Service

* **`websocket_routes.py`** â†’ `/audio` WebSocket receives mic audio â†’ streams to Deepgram
* **`transcript_service.py`** â†’ Handles Deepgram transcript events (partial & final)

### C. Groq Service (`groq_client.py`)

* Integrates with Groqâ€™s Llama 3-70B model
* Loads structured policies from **`prompt_config.json`**
* Returns **strict JSON output** with fields:

  ```json
  {
    "original_text": "...",
    "translated_text": "...",
    "detected_language": "en/es/mixed",
    "intent": "appointment",
    "urgent": false,
    "confidence": 0.87,
    "key_phrases": ["doctor", "visit"],
    "ai_response": "Weâ€™ve scheduled your appointment.",
    "ai_response_translated": "Weâ€™ve scheduled your appointment."
  }
  ```

### D. Mock Services (`mock_routes.py`)

* **`/mock/groq`** â†’ keyword â†’ mock JSON response
* **`/mock-conversation`** â†’ text â†’ Groq â†’ broadcasted response
* **`/conversation-history`** â†’ returns mock conversation history
* **`/reset-conversation`** â†’ clears history

### E. WebSocket Manager (`connection_manager.py`)

* Tracks active connections
* Provides `broadcast()` to push updates to all subscribed clients

### F. Clients

* **`mic_client.py`** â†’ streams mic â†’ `/audio`
* **`mic_and_transcript_client.py`** â†’ streams mic **and** listens on `/transcripts/stream` (demo-friendly)

---

## 4. How to Run

### Start server

```bash
uvicorn app.main:app --reload
```

### Run mic client (audio only â†’ Deepgram â†’ transcript)

```bash
python app/mic_client.py
```

### Run mic + transcript client (full loop: audio + AI response)

```bash
python app/mic_and_transcript_client.py
```

---

## 5. Testing Strategy

### A. Unit Tests

Run:

```bash
pytest -v
```

* `test_app.py` â€“ FastAPI HTTP routes
* `test_websockets.py` â€“ WebSocket `/audio` + `/transcripts/stream`

### B. Integration Tests

```bash
pytest tests/test_deepgram_integration.py -s
```

âš ï¸ Uses Deepgram credits (manual only)

### C. Postman Collection

* `POST /mock/groq` â†’ `{ "message": "I need to reschedule my caregiver" }`
* `POST /mock-conversation` â†’ free-text Groq simulation
* `GET /conversation-history`
* `POST /reset-conversation`

### D. Manual Demo

1. Start server
2. Run `mic_and_transcript_client.py`
3. Speak test phrases:

   * â€œI need to reschedule my caregiverâ€ â†’ intent: `caregiver_reschedule`
   * â€œMy mom has an emergencyâ€ â†’ intent: `urgent` â†’ response: *â€œAn admin will be with you shortly.â€*

---

## 6. Demo Strategy (Credits vs Mock)

### âœ… Credit-Free (Safe for loops/rehearsal)

* Use `/mock/groq` + `/mock-conversation` for scripted responses
* Use `/conversation-history` + `/reset-conversation` for demoing persistence

### âš¡ Real-Time (For WOW moment)

* Run `mic_and_transcript_client.py`
* Speak live â†’ Deepgram transcribes â†’ Groq analyzes â†’ AI admin responds in real time

---

## 7. Admin Training (Future)

* `prompt_config.json` â†’ holds rules for intent classification + response policies
* In future, Admin UI can update config in DB â†’ loaded dynamically â†’ injected into Groq prompt

---

Perfect ğŸ™Œ Letâ€™s put together a **Postman Demo Script** you can walk through during your presentation. This will simulate both **mock flow (credit-safe)** and **real flow (live WebSocket + Deepgram + Groq)**.

---

# ğŸš€ Servoice Demo Script (Postman)

### Prerequisites

* Start your backend:

  ```bash
  uvicorn app.main:app --reload
  ```
* Import the **Servoice Voice Assistant API Postman Collection** (the JSON I gave you earlier).
* Make sure your `.env` contains:

  * `DEEPGRAM_API_KEY`
  * `GROQ_API_KEY`

---

## 1. **Mock Flow (Credit-Free)**

Safe to run multiple times â€” uses your mock endpoints only.

### Step 1: Mock Groq Intent

**POST â†’ `/mock/groq`**
Body:

```json
{
  "message": "I need to reschedule my caregiver"
}
```

âœ… **Expected Output**:

```json
{
  "intent": "caregiver_reschedule",
  "translated_text": "I need to reschedule my caregiver",
  "ai_response": "Sure, let me connect you with our scheduling team.",
  "ai_response_translated": "Sure, let me connect you with our scheduling team.",
  "is_final": true,
  "timestamp": "2025-08-16T..."
}
```

---

### Step 2: Mock Conversation (Groq Live)

**POST â†’ `/mock-conversation`**
Body:

```json
{
  "text": "My mother has an emergency"
}
```

âœ… **Expected Output**:

```json
{
  "status": "success",
  "transcript": "My mother has an emergency",
  "intent": "urgent",
  "ai_response": "An admin will be with you shortly.",
  "language": "en",
  "urgent": true
}
```

---

### Step 3: Check Conversation History

**GET â†’ `/conversation-history`**

âœ… **Expected Output**:

```json
{
  "history": [
    {
      "transcript": "My mother has an emergency",
      "intent": "urgent",
      "ai_response": "An admin will be with you shortly."
    }
  ],
  "total_messages": 1
}
```

---

### Step 4: Reset Conversation

**POST â†’ `/reset-conversation`**

âœ… **Expected Output**:

```json
{ "status": "success", "message": "Conversation reset" }
```

---

## 2. **Real Flow (Optional - Uses Credits)**

âš ï¸ Only run this during the live demo when you want to impress â€” it will consume Deepgram + Groq credits.

### Step 1: Connect Audio Stream

* Go to Postmanâ€™s **WebSocket tab**
* URL â†’ `ws://localhost:8000/audio`
* Start sending **mic audio** (or pre-recorded audio via `mic_client.py`)

âœ… Postman log:

```
Connected â†’ /audio
```

---

### Step 2: Subscribe to Transcript Stream

* In another Postman tab
* URL â†’ `ws://localhost:8000/transcripts/stream`

âœ… You will see **real-time transcripts** appear:

```
ğŸ“ Transcript: hello
ğŸ“ Transcript: how are you doing
```

And final JSON message:

```json
{
  "transcript": "how are you doing",
  "intent": "inquiry",
  "ai_response": "We received your message and will respond soon.",
  "is_final": true,
  "timestamp": "2025-08-16T..."
}
```

---

## 3. **Suggested Demo Flow**

1. **Start with Mock** (no cost): Show intent detection + AI admin response.
2. **Show Conversation History**: â€œSee? It keeps track of messages.â€
3. **Live WebSocket Demo**: Say into your mic â†’ audience sees **real-time transcription + AI admin reply**.
4. **Reset Conversation**: Start fresh.

---

# ğŸš€ Servoice Postman

```json
{
  "info": {
    "name": "Servoice Voice Assistant API",
    "_postman_id": "servoce-api-demo",
    "description": "Postman collection for testing Servoice voice assistant backend (mock + real endpoints).",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "Mock - Groq",
      "request": {
        "method": "POST",
        "header": [{ "key": "Content-Type", "value": "application/json" }],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"message\": \"I need to reschedule my caregiver\"\n}"
        },
        "url": { "raw": "http://localhost:8000/mock/groq", "protocol": "http", "host": ["localhost"], "port": "8000", "path": ["mock", "groq"] }
      }
    },
    {
      "name": "Mock - Conversation",
      "request": {
        "method": "POST",
        "header": [{ "key": "Content-Type", "value": "application/json" }],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"text\": \"My mother has an emergency\"\n}"
        },
        "url": { "raw": "http://localhost:8000/mock-conversation", "protocol": "http", "host": ["localhost"], "port": "8000", "path": ["mock-conversation"] }
      }
    },
    {
      "name": "Get Conversation History",
      "request": {
        "method": "GET",
        "url": { "raw": "http://localhost:8000/conversation-history", "protocol": "http", "host": ["localhost"], "port": "8000", "path": ["conversation-history"] }
      }
    },
    {
      "name": "Reset Conversation",
      "request": {
        "method": "POST",
        "url": { "raw": "http://localhost:8000/reset-conversation", "protocol": "http", "host": ["localhost"], "port": "8000", "path": ["reset-conversation"] }
      }
    },
    {
      "name": "Real - WebSocket /audio",
      "event": [
        {
          "listen": "test",
          "script": {
            "exec": [
              "// Use Postman WebSocket testing tab",
              "// ws://localhost:8000/audio"
            ],
            "type": "text/javascript"
          }
        }
      ]
    },
    {
      "name": "Real - WebSocket /transcripts/stream",
      "event": [
        {
          "listen": "test",
          "script": {
            "exec": [
              "// Use Postman WebSocket testing tab",
              "// ws://localhost:8000/transcripts/stream"
            ],
            "type": "text/javascript"
          }
        }
      ]
    }
  ]
}
```

---

### âœ… How to Use

1. Open Postman
2. **Import** â†’ Paste raw text â†’ Save
3. Make sure your server is running (`uvicorn app.main:app --reload`)
4. Test:

   * `Mock - Groq` (simulated intent detection)
   * `Mock - Conversation` (sends text â†’ Groq â†’ broadcast)
   * `Get Conversation History`
   * `Reset Conversation`
   * WebSockets: use Postmanâ€™s **WebSocket tab** â†’ `ws://localhost:8000/transcripts/stream`

---
## ğŸ§ª Testing Notes â€“ Why We Use the Original Client

When writing unit tests for our FastAPI endpoints, we originally considered migrating to the modern `httpx.AsyncClient(app=app, base_url=...)` style.

However, the latest versions of `httpx` introduced **breaking changes** that removed the `app` parameter from the `AsyncClient` initializer. This caused errors like:

```
TypeError: AsyncClient.__init__() got an unexpected keyword argument 'app'
```

### âœ… Decision

For stability (and to avoid introducing dependency mismatches during demo prep), we decided to **stick with the original client setup** that already works and passes all tests. This ensures:

* Tests run reliably across environments (local + CI/CD)
* No version lock issues with `httpx` or `pytest-asyncio`
* Faster debugging and demo preparation

### ğŸ”® Future Migration (Optional)

After the demo, we can revisit migration to `AsyncClient` by updating to the latest `httpx` and rewriting tests like so:

```python
import pytest
from httpx import AsyncClient
from app.main import app

@pytest.mark.asyncio
async def test_mock_groq_hello():
    async with AsyncClient(base_url="http://test") as ac:
        response = await ac.post("/mock/groq", json={"message": "hello"})
        assert response.status_code == 200
```

This would require switching to a test client fixture that runs the FastAPI app inside a **TestServer** context (instead of `app=app`).

---